# ğŸ¤ Piper TTS - Interface de Treinamento de Vozes Clonadas

Uma interface web completa para treinar vozes personalizadas usando o Piper TTS, permitindo criar modelos de sÃ­ntese de voz com sua prÃ³pria voz ou qualquer voz desejada.

## ğŸš€ InstalaÃ§Ã£o RÃ¡pida

### 1. ConfiguraÃ§Ã£o AutomÃ¡tica
```bash
# Clone o repositÃ³rio (se ainda nÃ£o fez)
git clone https://github.com/rhasspy/piper.git
cd piper

# Execute o script de configuraÃ§Ã£o
python setup_piper_training.py
```

### 2. AtivaÃ§Ã£o do Ambiente
```bash
# Windows
venv\Scripts\activate

# Linux/macOS
source venv/bin/activate
```

### 3. Iniciar Interface
```bash
python web_interface.py
```

Acesse: **http://localhost:5000**

## ğŸ“‹ Requisitos do Sistema

### MÃ­nimos:
- Python 3.7+
- 8GB RAM
- 10GB espaÃ§o livre
- Placa de som

### Recomendados:
- Python 3.9+
- 16GB RAM
- GPU NVIDIA (para treinamento mais rÃ¡pido)
- 50GB espaÃ§o livre

### DependÃªncias do Sistema:
- **Linux:** `python3-dev`, `espeak-ng`, `build-essential`
- **macOS:** `espeak-ng` (via Homebrew)
- **Windows:** Visual Studio Build Tools

## ğŸ¯ Como Usar

### Passo 1: Preparar Dados de Ãudio

#### Requisitos de Ãudio:
- **Formato:** WAV (recomendado), MP3, FLAC
- **Qualidade:** 22kHz, mono
- **DuraÃ§Ã£o:** MÃ­nimo 30 minutos, recomendado 1-2 horas
- **Ambiente:** Silencioso, sem eco
- **Microfone:** Boa qualidade, consistente

#### Dicas de GravaÃ§Ã£o:
- Mantenha distÃ¢ncia consistente do microfone
- Fale com tom natural e velocidade normal
- Evite respiraÃ§Ã£o audÃ­vel
- Pause entre frases
- Use textos variados (notÃ­cias, literatura, conversaÃ§Ã£o)

### Passo 2: Criar Arquivo Metadata

Crie um arquivo `metadata.csv` com o formato:
```csv
id|texto
```

**Exemplo:**
```csv
audio001|OlÃ¡, este Ã© um exemplo de texto para treinamento.
audio002|A qualidade do Ã¡udio Ã© muito importante para bons resultados.
audio003|Recomenda-se pelo menos trinta minutos de Ã¡udio limpo.
```

Para mÃºltiplos falantes:
```csv
id|speaker|texto
audio001|pessoa1|Primeira pessoa falando este texto.
audio002|pessoa2|Segunda pessoa com voz diferente.
```

### Passo 3: Upload na Interface

1. Acesse a aba **"Upload de Dados"**
2. Digite o nome do modelo
3. Selecione os arquivos de Ã¡udio
4. FaÃ§a upload do metadata.csv
5. Clique em **"Enviar Arquivos"**

### Passo 4: Configurar Treinamento

1. VÃ¡ para a aba **"Treinamento"**
2. Selecione o modelo uploadado
3. Configure os parÃ¢metros:
   - **Idioma:** pt-br (PortuguÃªs Brasil)
   - **Qualidade:** Medium (balanceado)
   - **Taxa de Amostragem:** 22050 Hz
   - **Falante Ãºnico:** Marque se for uma sÃ³ voz

### Passo 5: Iniciar Treinamento

1. Clique em **"Iniciar Treinamento"**
2. Monitore o progresso na interface
3. O processo pode levar de 30 minutos a vÃ¡rias horas
4. Acompanhe o log para verificar se estÃ¡ tudo correndo bem

### Passo 6: Testar o Modelo

1. ApÃ³s o treinamento, vÃ¡ para **"Modelos"**
2. Verifique se o modelo aparece como completo
3. Na aba **"Teste de Voz"**:
   - Selecione o modelo treinado
   - Digite um texto de teste
   - Clique em **"Gerar Ãudio"**
   - OuÃ§a o resultado

## âš™ï¸ ConfiguraÃ§Ãµes AvanÃ§adas

### Qualidades de Modelo:
- **Baixa (16kHz):** Mais rÃ¡pido, menor qualidade
- **MÃ©dia (22kHz):** Balanceado, recomendado
- **Alta (22kHz):** Melhor qualidade, mais lento

### ParÃ¢metros de Treinamento:
- **Ã‰pocas:** NÃºmero de ciclos de treinamento
- **Batch Size:** Quantidade de dados processados por vez
- **Learning Rate:** Velocidade de aprendizado

### Fine-tuning:
Para melhorar um modelo existente, vocÃª pode usar checkpoints prÃ©-treinados disponÃ­veis em:
https://huggingface.co/datasets/rhasspy/piper-checkpoints

## ğŸ”§ SoluÃ§Ã£o de Problemas

### Erro de MemÃ³ria:
- Reduza o batch size
- Use qualidade "baixa"
- Feche outros programas

### Ãudio com RuÃ­do:
- Use software de limpeza de Ã¡udio (Audacity)
- Grave em ambiente mais silencioso
- Verifique configuraÃ§Ãµes do microfone

### Treinamento Lento:
- Use GPU se disponÃ­vel
- Reduza duraÃ§Ã£o dos Ã¡udios
- Use qualidade "baixa" para testes

### Modelo nÃ£o Funciona:
- Verifique se tem dados suficientes
- Confirme formato do metadata.csv
- Teste com textos similares aos de treinamento

## ğŸ“ Estrutura de Arquivos

```
piper/
â”œâ”€â”€ web_interface.py          # Interface web principal
â”œâ”€â”€ setup_piper_training.py   # Script de configuraÃ§Ã£o
â”œâ”€â”€ install_dependencies.py   # Instalador de dependÃªncias
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html           # Interface HTML
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/style.css        # Estilos
â”‚   â”œâ”€â”€ js/script.js         # JavaScript
â”‚   â””â”€â”€ audio/               # Ãudios gerados
â”œâ”€â”€ uploads/                 # Arquivos enviados
â”œâ”€â”€ training_data/           # Dados de treinamento
â”œâ”€â”€ trained_models/          # Modelos finalizados
â””â”€â”€ examples/                # Arquivos de exemplo
```

## ğŸµ Formatos de SaÃ­da

### Arquivos Gerados:
- **modelo.onnx:** Modelo neural otimizado
- **modelo.onnx.json:** ConfiguraÃ§Ãµes do modelo
- **checkpoints/:** Pontos de salvamento durante treinamento

### Uso dos Modelos:
```bash
# Via linha de comando
echo "Texto para falar" | piper -m modelo.onnx --output_file saida.wav

# Via Python
import piper
model = piper.PiperVoice.load("modelo.onnx")
audio = model.synthesize("Texto para falar")
```

## ğŸ¤ ContribuiÃ§Ã£o

Para contribuir com melhorias:

1. Fork o repositÃ³rio
2. Crie uma branch para sua feature
3. FaÃ§a commit das mudanÃ§as
4. Abra um Pull Request

## ğŸ“š Recursos Adicionais

- [DocumentaÃ§Ã£o Oficial Piper](https://github.com/rhasspy/piper)
- [Guia de Treinamento Original](TRAINING.md)
- [Modelos PrÃ©-treinados](https://huggingface.co/rhasspy)
- [Comunidade Rhasspy](https://community.rhasspy.org/)

## ğŸ“„ LicenÃ§a

Este projeto segue a licenÃ§a MIT do Piper TTS original.

## ğŸ†˜ Suporte

Para problemas especÃ­ficos:
1. Verifique os logs na interface
2. Consulte a seÃ§Ã£o de soluÃ§Ã£o de problemas
3. Abra uma issue no GitHub
4. Participe da comunidade Rhasspy

---

**Desenvolvido com â¤ï¸ para a comunidade de sÃ­ntese de voz**